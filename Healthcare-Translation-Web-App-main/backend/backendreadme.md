# Speech Recognition, Translation, and Text-to-Speech API

This project provides a FastAPI-based web service that performs speech recognition, text translation, and text-to-speech functionality. The service includes endpoints to upload audio files, recognize speech, translate text, and generate speech from the translated text.

The audio files are encrypted to ensure security, and the service uses Google's Text-to-Speech (gTTS) and the Ollama model for text translation.

## Features

- **Audio Upload & Speech Recognition**: Upload audio files, and the system will recognize the speech and return the text.
- **Text Translation**: Translate text from one language to another using the local Ollama model API.
- **Text-to-Speech**: Generate speech from translated text in various languages.
- **Audio Encryption**: The audio files are encrypted for security purposes before being returned to the user.
- **Multi-Language Support**: The system supports multiple languages for text-to-speech and translation.

## Dependencies

To run this project, ensure you have the following dependencies installed:

- `fastapi` – Web framework for building the API.
- `uvicorn` – ASGI server to run the FastAPI app.
- `gtts` – Google Text-to-Speech library.
- `cryptography` – For encrypting and decrypting audio files.
- `requests` – For making HTTP requests to the Ollama model.
- `speechrecognition` – For speech-to-text conversion.
- `python-dotenv` (optional) – For managing environment variables.

To install these dependencies, use the following:

```bash
pip install fastapi uvicorn gtts cryptography requests SpeechRecognition python-dotenv
```
Setup
Run the Ollama Model Locally

Make sure the Ollama model server is running on your local machine. The FastAPI application interacts with the Ollama model API (default URL: http://localhost:11434/api/generate) to perform text translation.

Run the FastAPI Server

To run the FastAPI server, use the following command:

```bash
uvicorn main:app --reload
```
This will start the server on http://localhost:8000.

## API Endpoints
1. ```/upload_audio [POST]```

Description: This endpoint accepts an audio file, processes it, and returns the recognized text.

Request:
file: The audio file to be uploaded (e.g., .wav file).

Response:
A JSON response containing the recognized text or an error message.
Example Request:

```bash
POST /upload_audio

{
    "file": "<audio_file>"
}
```
## 2. /translate/ [POST]
Description: This endpoint accepts text and translates it from one language to another. It also generates a speech audio file for the translated text.

Request:

text: The text to be translated.

input_lang_code: The input language code (e.g., "en" for English).

output_lang_code: The output language code (e.g., "es" for Spanish).

Response:
A JSON response containing the original text, translated text, and a path to the encrypted audio file of the translated text.
Example Request:

```bash
POST /translate/
{
    "text": "Hello, how are you?",
    "input_lang_code": "en",
    "output_lang_code": "es"
}
```
Example Response:

```bash
{
    "original_text": "Hello, how are you?",
    "translated_text": "Hola, ¿cómo estás?",
    "audio_file": "path_to_encrypted_audio.mp3"
}
```
## 3. /audio/{filename} [GET]
Description: This endpoint serves the decrypted audio file generated by the /translate/ endpoint.

Request:

filename: The name of the encrypted audio file.

Response:
The decrypted audio file in .mp3 format.
Example Request:

```bash
GET /audio/path_to_encrypted_audio.mp3
```
### Encryption
The generated audio files are encrypted using a symmetric key algorithm (Fernet) to ensure that the audio files are securely transmitted. Upon request, the audio files are decrypted before being sent to the client.

### Logging
The application logs all important events (e.g., errors, recognized text, translation responses) into a file named app.log.

### Error Handling
The API returns meaningful error messages in case of failures. Possible errors include:

 Invalid Audio File: If the audio file cannot be recognized or processed.
 Translation Failure: If the Ollama model fails to return a translation.
Encryption/Decryption Issues: Errors related to encryption or decryption of audio files.

Example Flow

Upload an audio file to the /upload_audio endpoint.

The server recognizes the speech in the uploaded audio and returns the recognized text.

Use the /translate/ endpoint to translate the recognized text into another language and generate speech in the translated language.

Download the encrypted audio file.


Use the /audio/{filename} endpoint to retrieve the decrypted audio.

## License
``` 
This project is licensed under the MIT License - see the LICENSE file for details.
```
## Acknowledgements
Google Text-to-Speech (gTTS): Used for generating speech from text.
SpeechRecognition Library: Used for speech-to-text conversion.
Ollama API: Local model for text translation.
markdown
Copy

### Key Sections in the README:
1. **Features** – Overview of what the project offers.
2. **Dependencies** – Libraries required to run the application.
3. **Setup** – Instructions on running the application and the Ollama model.
4. **API Endpoints** – Detailed information on the available routes, request formats, and example responses.
5. **Encryption** – Explanation of how audio files are encrypted and decrypted.
6. **Logging** – Information about the logging functionality.
7. **Error Handling** – Explanation of potential error types and handling.
8. **Example Flow** – Describes how users can interact with the API endpoints in sequence.

This should provide a clear and professional explanation of your FastAPI project.