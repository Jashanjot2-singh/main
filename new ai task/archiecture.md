# ğŸ“˜ Resume Screening Tool â€“ Architecture Overview

This document explains the full system architecture of the AI-powered Resume Screening Tool using Node.js + React + RAG (Retrieval-Augmented Generation).

## ğŸ”· 1. High-Level Overview

The system consists of:

- **Frontend (React + TypeScript)**
- **Backend (Node.js + Express + TypeScript)**
- **Gemini 2.5 Flash** â†’ Used for match analysis, question answering, and RAG final generation
- **Gemini Embeddings 3072-D** â†’ Used to create embeddings for resume chunks
- **Qdrant Cloud** â†’ Stores vector embeddings for retrieval
- **Ollama (local)** â†’ Used optionally for embedding fallback (nomic-embed-text)
- **MySQL (XAMPP)** â†’ Stores chat history (returns last 5 messages per session)
- **pdf-parse** â†’ Extracts text from PDF documents

## ğŸ”· 2. System Architecture Flow

**React UI (Upload, Analysis, Chat)**
- â†’ HTTP Requests
- â†’ **Node.js API (Express + TypeScript)**
- â†’ **Document Processing Layer (pdf-parse â†’ text chunks)**
- â†’ **Gemini Embeddings 3072D (Create vector embeddings)**
- â†’ **Qdrant Vector DB (Store resume embeddings)**
- â†’ **RAG Retrieval (Search relevant chunks)**
- â†’ **Gemini 2.5 Flash LLM (Generates final answers)**
- â†’ **MySQL XAMPP (Save last 5 chat history)**
- â†’ **Response to UI**

## ğŸ”· 3. Backend Architecture

### 3.1 Directory Structure
```
backend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ analyze.ts
â”‚   â”‚   â””â”€â”€ chat.ts
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ gemini.ts
â”‚   â”‚   â”œâ”€â”€ embeddings.ts
â”‚   â”‚   â”œâ”€â”€ vectorDB.ts
â”‚   â”‚   â”œâ”€â”€ rag.ts
â”‚   â”‚   â””â”€â”€ mysql.ts
â”‚   â”œâ”€â”€ utils/pdfParser.ts
â”‚   â””â”€â”€ index.ts
```

## ğŸ”· 4. Document Processing Pipeline

### 4.1 PDF â†’ Text Extraction

**pdf-parse** is used to extract plain text from resume and job description.

### 4.2 Chunking Strategy

- **Chunk size:** 500 words
- **Overlap:** 50 words

Chunking improves:
- semantic search,
- retrieval accuracy,
- RAG context relevance.

## ğŸ”· 5. Embeddings Architecture

Your updated architecture uses:

âœ… **Gemini Embeddings 3072-Dimensional Vectors**

The embedding model used:
```
gemini-embedding-2.0  (3072 dimensions)
```

### Why 3072?

- Larger vector space
- Higher semantic richness
- Better matching for resumes with mixed structure
- Ideal for skills extraction & technical document retrieval

### Flow:

- resume chunk â†’ Gemini Embeddings (3072D) â†’ Qdrant
- question â†’ Gemini Embeddings (3072D) â†’ Qdrant search

## ğŸ”· 6. Vector Database Architecture (Qdrant)

Each session creates one collection or uses a common collection with filtering.

### Stored fields:

| Field | Description |
|-------|-------------|
| id | UUID of chunk |
| text | Resume chunk text |
| embedding | 3072-D vector |
| session_id | Group by user session |

### Distance Metric

**cosine**

## ğŸ”· 7. RAG Architecture

### 7.1 Retrieval Flow

1. Convert user question â†’ 3072-D embedding (Gemini Embedding model)
2. Perform a vector similarity search in Qdrant
3. Retrieve top K relevant chunks (K=5)
4. Build context:
   - [Retrieved Resume Chunks]
   - + Last 5 chat messages (MySQL)
   - + Job Description (optional)
5. Invoke Gemini 2.5 Flash with structured system prompt
6. Generate final answer

## ğŸ”· 8. Chat History Layer (MySQL)

### Table Structure
```sql
id INT AUTO_INCREMENT PRIMARY KEY
session_id VARCHAR(255)
role ENUM('user','assistant')
message TEXT
created_at TIMESTAMP
```

### Rules:

- Store every message
- Always retrieve only last 5 messages
- Delete old messages periodically

## ğŸ”· 9. Resume Match Analysis Architecture

For `/api/analyze`:

1. Extract resume & JD text
2. Send both to Gemini 2.5 Flash
3. Gemini returns structured JSON:
```json
   {
     "score": 75,
     "strengths": [...],
     "gaps": [...],
     "insights": [...]
   }
```
4. Resume text is chunked â†’ embedded â†’ stored in Qdrant
5. Session ID returned to frontend

## ğŸ”· 10. Frontend Architecture

Built using:
- React + TypeScript
- Vite
- Tailwind CSS
- shadcn/ui

### Modules:
- `UploadSection.tsx`
- `AnalysisResults.tsx`
- `ChatInterface.tsx`

## ğŸ”· 11. RAG vs NON-RAG Behavior

| Feature | Without RAG | With RAG |
|---------|-------------|----------|
| Uses entire resume? | Yes (BAD) | No |
| Retrieval? | âŒ | âœ”ï¸ |
| Embeddings? | âŒ | âœ”ï¸ Gemini 3072D |
| Vector Search | âŒ | âœ”ï¸ Qdrant |
| Accuracy | Low | Very High |
| Cost | More (large input) | Less |

Your implementation uses true RAG â€” correct and required.

## ğŸ”· 12. Component Flow

**Frontend**
- â†’ REST API Calls
- â†’ **Express API**
  - â†’ **PDF Parser**
  - â†’ **Gemini API**
  - â†’ **Embedding Service**
- â†’ **Resume Analyzer**
  - â†’ **Qdrant Vector DB**
  - â†’ **MySQL Storage**

## ğŸ”· 13. Key Highlights

- âœ” Uses Gemini Embedding 3072D
- âœ” True RAG: embedding â†’ search â†’ retrieval â†’ LLM
- âœ” Qdrant Cloud with HTTPS + API Key
- âœ” MySQL chat memory (last 5 messages only)
- âœ” Session-based isolation
- âœ” Full end-to-end AI workflow

## ğŸ”· 14. Future Enhancements

- Add Redis cache for faster retrieval
- Add multi-resume comparison
- Add user authentication (JWT)
- Add queueing for large files